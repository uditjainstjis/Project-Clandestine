{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8022663,"sourceType":"datasetVersion","datasetId":4727630}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nfrom category_encoders import TargetEncoder\nfrom scipy.sparse import hstack\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:53:59.778020Z","iopub.execute_input":"2025-11-19T12:53:59.778914Z","iopub.status.idle":"2025-11-19T12:55:38.768048Z","shell.execute_reply.started":"2025-11-19T12:53:59.778880Z","shell.execute_reply":"2025-11-19T12:55:38.767128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv(\"/kaggle/input/liar-dataset/train.tsv\", sep=\"\\t\", header=None)\ndf.columns = [\"id\",\"label\",\"statement\",\"subjects\",\"speaker\",\"speaker_job\",\"state\",\"party\",\n              \"barely_true_counts\",\"false_counts\",\"half_true_counts\",\"mostly_true_counts\",\n              \"pants_on_fire_counts\",\"context\"]\n\n# Binary label\ntrue_labels = [\"true\", \"mostly-true\", \"half-true\"]\ndf[\"binary_label\"] = df[\"label\"].apply(lambda x: \"true\" if x in true_labels else \"false\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:56:29.487878Z","iopub.execute_input":"2025-11-19T12:56:29.488233Z","iopub.status.idle":"2025-11-19T12:56:29.562280Z","shell.execute_reply.started":"2025-11-19T12:56:29.488207Z","shell.execute_reply":"2025-11-19T12:56:29.561239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocess text function\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words(\"english\"))\ndef preprocess(text):\n    text = str(text).lower()\n    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n    words = nltk.word_tokenize(text)\n    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n    return \" \".join(words)\n\n# Clean text columns\ndf[\"clean_statement\"] = df[\"statement\"].apply(preprocess)\ndf[\"clean_subjects\"] = df[\"subjects\"].fillna(\"\").apply(preprocess)\ndf[\"clean_context\"] = df[\"context\"].fillna(\"\").apply(preprocess)\n\n# TF-IDF for text columns\ntfidf_statement = TfidfVectorizer(max_features=12000, ngram_range=(1,3), min_df=3, max_df=0.9)\nX_statement = tfidf_statement.fit_transform(df[\"clean_statement\"])\n\ntfidf_subjects = TfidfVectorizer(max_features=5000)\nX_subjects = tfidf_subjects.fit_transform(df[\"clean_subjects\"])\n\ntfidf_context = TfidfVectorizer(max_features=5000)\nX_context = tfidf_context.fit_transform(df[\"clean_context\"])\n\n# Numeric features scaled\nnumeric_cols = [\"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\"]\nscaler = StandardScaler()\nX_numeric = scaler.fit_transform(df[numeric_cols].fillna(0))\n\n# Target encoding for speaker and speaker_job\nte_speaker = TargetEncoder()\ndf['speaker_encoded'] = te_speaker.fit_transform(df['speaker'], df['binary_label'].map({'false':0,'true':1}))\n\nte_job = TargetEncoder()\ndf['speaker_job_encoded'] = te_job.fit_transform(df['speaker_job'], df['binary_label'].map({'false':0,'true':1}))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:02:46.581484Z","iopub.execute_input":"2025-11-19T13:02:46.581912Z","iopub.status.idle":"2025-11-19T13:02:54.009213Z","shell.execute_reply.started":"2025-11-19T13:02:46.581885Z","shell.execute_reply":"2025-11-19T13:02:54.007837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-hot encoding for state and party\nfrom sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\nX_cat = ohe.fit_transform(df[['state','party']].fillna(\"unknown\"))\n\n# Combine all features\nimport numpy as np\nX_combined = hstack([X_statement, X_subjects, X_context, X_numeric, \n                     np.array(df[['speaker_encoded','speaker_job_encoded']]), X_cat])\n\n# Labels\nle = LabelEncoder()\ny_numeric = le.fit_transform(df[\"binary_label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:03:10.330926Z","iopub.execute_input":"2025-11-19T13:03:10.331252Z","iopub.status.idle":"2025-11-19T13:03:10.357197Z","shell.execute_reply.started":"2025-11-19T13:03:10.331230Z","shell.execute_reply":"2025-11-19T13:03:10.356235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X_combined, y_numeric, test_size=0.2, random_state=42)\n\n# Train Logistic Regression\nlogreg = LogisticRegression(max_iter=5000, class_weight=\"balanced\", solver=\"liblinear\")\nlogreg.fit(X_train, y_train)\nlog_pred = logreg.predict(X_test)\n\n# Train XGBoost\nxgb = XGBClassifier(n_estimators=500, learning_rate=0.1, max_depth=6, eval_metric='logloss')\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)\n\n# Evaluate models\nmodels = {\"Logistic Regression\": log_pred, \"XGBoost\": xgb_pred}\nfor name, pred in models.items():\n    print(f\"=== {name} ===\")\n    print(\"Accuracy:\", accuracy_score(y_test, pred))\n    print(\"F1 Score:\", f1_score(y_test, pred, average=\"macro\"))\n    print(classification_report(y_test, pred))\n    \n    cm = confusion_matrix(y_test, pred)\n    plt.figure(figsize=(5,4))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"False\",\"True\"], yticklabels=[\"False\",\"True\"])\n    plt.title(f\"Confusion Matrix - {name}\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\n\n# Display top TF-IDF features for TRUE and FALSE from statements\nimport numpy as np\nfeature_array = np.array(tfidf_statement.get_feature_names_out())\ntrue_class_idx = np.where(y_numeric==1)[0]\nfalse_class_idx = np.where(y_numeric==0)[0]\ntfidf_mean_true = np.array(X_statement[true_class_idx].mean(axis=0)).flatten()\ntfidf_mean_false = np.array(X_statement[false_class_idx].mean(axis=0)).flatten()\n\ntop_true_idx = tfidf_mean_true.argsort()[-20:][::-1]\ntop_false_idx = tfidf_mean_false.argsort()[-20:][::-1]\n\nprint(\"Top words predicting TRUE:\", feature_array[top_true_idx])\nprint(\"Top words predicting FALSE:\", feature_array[top_false_idx])\n\n# Feature importance from XGBoost\nimportances = xgb.feature_importances_\ntop_idx = np.argsort(importances)[-20:][::-1]\nprint(\"Top 20 important features (XGBoost):\")\nfor idx in top_idx:\n    print(f\"{idx}: Importance={importances[idx]}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:03:13.903520Z","iopub.execute_input":"2025-11-19T13:03:13.903897Z","iopub.status.idle":"2025-11-19T13:03:40.234360Z","shell.execute_reply.started":"2025-11-19T13:03:13.903871Z","shell.execute_reply":"2025-11-19T13:03:40.233413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Create a dataframe for plotting\nresults_df = pd.DataFrame({\n    'Model': ['Logistic Regression', 'XGBoost'],\n    'Accuracy': [accuracy_score(y_test, log_pred), accuracy_score(y_test, xgb_pred)],\n    'F1 Macro': [f1_score(y_test, log_pred, average=\"macro\"), f1_score(y_test, xgb_pred, average=\"macro\")]\n})\n\n# Plotting\nax = results_df.set_index('Model').plot(kind='bar', figsize=(9, 5), color=['#1f77b4', '#ff7f0e'])\nplt.title('Model Performance: Accuracy vs F1 Score')\nplt.ylabel('Score')\nplt.ylim(0, 1.1)\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.legend(loc='lower right')\n\n# Add labels on bars\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:30:19.228648Z","iopub.execute_input":"2025-11-19T13:30:19.229016Z","iopub.status.idle":"2025-11-19T13:30:19.420520Z","shell.execute_reply.started":"2025-11-19T13:30:19.228992Z","shell.execute_reply":"2025-11-19T13:30:19.419816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Gather all feature names in the exact order of hstack\nnames_statement = tfidf_statement.get_feature_names_out()\nnames_subjects = tfidf_subjects.get_feature_names_out()\nnames_context = tfidf_context.get_feature_names_out()\nnames_numeric = numeric_cols\nnames_speakers = ['speaker_encoded', 'speaker_job_encoded']\nnames_cat = ohe.get_feature_names_out()\n\n# Combine them\nall_feature_names = np.concatenate([\n    names_statement, \n    names_subjects, \n    names_context, \n    names_numeric, \n    names_speakers, \n    names_cat\n])\n\n# 2. Map importance to names\nimportances = xgb.feature_importances_\nindices = np.argsort(importances)[-10:] # Top 10\n\nplt.figure(figsize=(10, 6))\nplt.title('Top 10 Feature Importances (XGBoost)')\nplt.barh(range(len(indices)), importances[indices], color='teal', align='center')\nplt.yticks(range(len(indices)), [all_feature_names[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:31:40.976714Z","iopub.execute_input":"2025-11-19T13:31:40.977089Z","iopub.status.idle":"2025-11-19T13:31:41.193589Z","shell.execute_reply.started":"2025-11-19T13:31:40.977066Z","shell.execute_reply":"2025-11-19T13:31:41.192907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 1. Re-generate feature names (Crucial so the plot isn't just \"Feature 0, Feature 1\")\n# (This logic mirrors your hstack structure)\nnames_statement = tfidf_statement.get_feature_names_out()\nnames_subjects = tfidf_subjects.get_feature_names_out()\nnames_context = tfidf_context.get_feature_names_out()\nnames_numeric = numeric_cols # [\"barely_true_counts\", \"false_counts\", etc.]\nnames_speakers = ['speaker_encoded', 'speaker_job_encoded']\nnames_cat = ohe.get_feature_names_out()\n\nall_feature_names = np.concatenate([\n    names_statement, \n    names_subjects, \n    names_context, \n    names_numeric, \n    names_speakers, \n    names_cat\n])\n\n# 2. Initialize the SHAP Explainer with your XGBoost model\n# We use a subset of X_test (e.g., first 1000 rows) to speed up calculation if dataset is huge\nexplainer = shap.TreeExplainer(xgb)\nshap_values = explainer.shap_values(X_test)\n\n# 3. Create the Summary Plot\nplt.figure(figsize=(10, 8))\nshap.summary_plot(shap_values, X_test, feature_names=all_feature_names, show=False)\nplt.title(\"SHAP Summary Plot: Feature Impact on 'True' vs 'False'\", fontsize=14)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:32:56.697131Z","iopub.execute_input":"2025-11-19T13:32:56.697445Z","iopub.status.idle":"2025-11-19T13:33:09.923367Z","shell.execute_reply.started":"2025-11-19T13:32:56.697426Z","shell.execute_reply":"2025-11-19T13:33:09.922461Z"}},"outputs":[],"execution_count":null}]}