# Project Clandestine: AI Information Verification System

## ðŸŽ¯ Project Overview

**Mission**: Building a comprehensive AI information verification system to combat the growing issue of AI-generated misinformation polluting the web and creating feedback loops of false information.

### The Problem
AI is slowly poisoning its own well. With 1200+ AI-generated content sites and a dangerous feedback loop where:
1. AI/LLM gives wrong info â†’
2. Someone publishes that info on reputed sites â†’
3. Content gets views and engagement â†’
4. Next AI models see high-engagement content as "must be true" â†’
5. Misinformation becomes a trusted source â†’ cycle repeats

### Our Solution
A verification system that doesn't just fetch information but actively verifies and proves it through trusted sources and cross-referencing.

## ðŸ—ï¸ System Architecture

### Core Flow
```
User prompt â†’ Router (classifier) â†’ Crawler â†’ Knowledge Base â†’ LLM (summarizer)
```

### Key Components

#### 1. Parameter Selection System
- Define what we consider "correct" (research papers, authoritative sources)
- Domain-specific parameter selection
- Dynamic trust scoring for sources

#### 2. Verification Pipeline
- **Option A**: Use Perplexity API â†’ scrape research papers â†’ LLM parsing
- **Option B**: Custom search â†’ LLM-generated search queries â†’ web scraping â†’ relevance filtering

#### 3. Trust Scoring Algorithm

**Dynamic Trust Score (0-1 scale)**

| Factor | Description | Scoring Rule |
|--------|-------------|-------------|
| Domain Reputation | Authority level | 0.9 for .edu/.gov; 0.8 for .org |
| Source Verification | Cross-citations | +0.05 per citation |
| Fact-Check Record | Misinformation history | -0.2 for false reports |
| Recency | Data freshness | -0.1 for >2 years old |
| Consistency | Cross-source matching | +0.2 for high similarity |

**Final Score Calculation:**
```
FinalScore = 0.4D + 0.3C + 0.2R + 0.1F
```
Where: D=Domain trust, C=Cross-source consistency, R=Recency, F=Fact-check verification

**Trust Levels:**
- â‰¥0.75: "Trusted"
- 0.5-0.75: "Partially Trusted"
- <0.5: "Untrusted"

#### 4. Cross-Verification System
- Search 3-5 trusted sources for same claim
- Compare entities, dates, numbers
- Use NLP techniques (BERT embeddings, RoBERTa-large-mnli)
- Textual entailment analysis

## ðŸ“Š Example Verification Flow

**User Query**: "NASA confirms alien life on Mars."

1. **Router**: Classifies as "Science News"
2. **Crawler**: Searches NASA, Reuters, BBC Science
3. **Knowledge Base**: No official NASA report found
4. **Cross-check**: Reuters/BBC report "No official confirmation"
5. **Fact-check API**: Snopes lists as false
6. **Result**: Trust score = 0.18 â†’ **FAKE**

## ðŸŽ¯ Precision vs Recall Strategy

### High Precision (Minimize False Positives)
- When false alarms cause serious harm
- Examples: Reputation damage, legal action, wrongful content takedown

### High Recall (Minimize False Negatives)
- When missing real issues is dangerous
- Examples: Health misinformation, safety-critical information

## ðŸŒ Blue Tick User System
- Verified trustworthy users across the internet
- Training data based on their contributions
- Continuous knowledge base refinement

## ðŸ”— Supporting Evidence

### Academic Research on AI Content Pollution
- [ScienceDirect - Domain General Cognitive Ability](https://www.sciencedirect.com/topics/psychology/domain-general-cognitive-ability)
- [ScienceDirect - Research Article](https://www.sciencedirect.com/science/article/abs/pii/S1364661312000824)
- [PhD Discussion Thread](https://bsky.app/profile/irisvanrooij.bsky.social/post/3lvm7x4oo2k2o)

### Open Letters from Academia
- [1100+ Professor Signatures - Stop Uncritical AI Adoption in Academia](https://openletter.earth/open-letter-stop-the-uncritical-adoption-of-ai-technologies-in-academia-b65bba1e)
- [Educators Against GenAI in Education](https://openletter.earth/an-open-letter-from-educators-who-refuse-the-call-to-adopt-genai-in-education-cb4aee75)

### Related Video
- [AI Information Problem Explanation](https://www.youtube.com/watch?v=_zfN9wnPvU0)

## ðŸ‘¥ Team & Responsibilities

### Current Team
- **Udit**: Research Lead - Core problem analysis and solution design
- **Divya**: Research - Trust scoring and verification algorithms
- **Rishik**: Research - Cross-verification and NLP implementation

## ðŸ“ Repository Structure

```
/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ api-reference.md        # API documentation
â”‚   â”œâ”€â”€ architecture.md         # System architecture details
â”‚   â”œâ”€â”€ contributing.md         # Contribution guidelines
â”‚   â””â”€â”€ use-cases.md            # Detailed use cases
â”œâ”€â”€ research/                    # Research materials
â”‚   â”œâ”€â”€ papers/                 # Academic papers and references
â”‚   â”œâ”€â”€ experiments/            # Research experiments
â”‚   â””â”€â”€ findings/               # Research findings and notes
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ crawler/                # Web crawling modules
â”‚   â”œâ”€â”€ classifier/             # Content classification
â”‚   â”œâ”€â”€ verifier/               # Verification engine
â”‚   â””â”€â”€ api/                    # API endpoints
â”œâ”€â”€ daily-progress/             # Daily progress tracking
â”‚   â”œâ”€â”€ templates/              # Log templates
â”‚   â””â”€â”€ logs/                   # Individual daily logs
â””â”€â”€ tests/                      # Test suites
    â”œâ”€â”€ unit/                   # Unit tests
    â””â”€â”€ integration/            # Integration tests
```

## ðŸš€ Getting Started

### Prerequisites
- Python 3.8+
- Node.js 16+
- Docker (optional)

### Installation
```bash
git clone https://github.com/uditjainstjis/Project-Clandestine.git
cd Project-Clandestine
pip install -r requirements.txt
```

### Quick Start
```bash
# Run the verification system
python src/main.py --query "your query here"

# Start development server
npm run dev
```

## ðŸ“ˆ Progress Tracking

### Phase 1: Research & Foundation (Current)
- [x] Problem identification and analysis
- [x] Core architecture design
- [x] Trust scoring algorithm design
- [ ] Initial prototype development

### Phase 2: Development
- [ ] Core verification engine
- [ ] API development
- [ ] Web interface
- [ ] Testing suite

### Phase 3: Enhancement
- [ ] Advanced NLP integration
- [ ] Real-time verification
- [ ] Browser extension
- [ ] Mobile app

## ðŸ¤ Contributing

See [CONTRIBUTING.md](docs/contributing.md) for detailed contribution guidelines.

### Daily Progress Logging
All team members should log daily progress in `daily-progress/logs/YYYY-MM-DD-[name].md`

## ðŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ðŸ”® Future Vision

Building the next generation of information verification - a system that doesn't just compete with Perplexity but sets the standard for verified, trustworthy AI-powered information retrieval.

---

**Note**: This is an active research project. The system is currently in the research and development phase. Contributions and feedback are welcome!
